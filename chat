import re
import pandas as pd

# --- 1) Column mapping for YOUR file ---
RENAME = {
    'Motor_Size_in_cc': 'Motor_cc',
    'Motor_Power_in_kw': 'Power_kW',
    'CO2_Emission_in_g_km': 'CO2_g_per_km',
    'Average_Fuel_Consumption_in_liter_100km': 'Fuel_L_per_100km',
    'Average_Electricity_Consumption_in_Kwh_100km': 'Elec_kWh_per_100km',
    'Electric_Range_in_km': 'ERange_km',
    'Vehicle_List_Price_including_Discounts_in_USD': 'Price_USD',
}
TARGET = ['Motor_cc','Power_kW','CO2_g_per_km','Fuel_L_per_100km','Elec_kWh_per_100km','ERange_km','Price_USD']

# columns where zero is not realistic and should be excluded in the "clean" views
ZERO_BAD = {'Motor_cc','Power_kW','Fuel_L_per_100km','Price_USD'}

# --- 2) Helper: strong numeric coercion (handles $ , kW, spaces, etc.) ---
def to_number(series: pd.Series) -> pd.Series:
    def _clean(x):
        if pd.isna(x): return pd.NA
        s = str(x).strip()
        if s in {"", "-", "--", "NA", "N/A", "nan"}: return pd.NA
        # remove currency and unit clutter; keep digits, dot, minus
        s = re.sub(r"[,$£€\s]", "", s)
        s = re.sub(r"[a-zA-Z_()%]+", "", s)  # drop trailing unit strings like "kW", "km"
        return s
    s = series.map(_clean)
    return pd.to_numeric(s, errors="coerce")

# --- 3) Load + rename (assumes df already loaded; otherwise do df = pd.read_csv(...)) ---
# df = pd.read_csv("your_data.csv")
df = df.rename(columns=RENAME)

present = [c for c in TARGET if c in df.columns]
if not present:
    raise ValueError("None of the target numeric columns are present after renaming.")

# Coerce all target columns to numeric (robust)
for c in present:
    df[c] = to_number(df[c])

# Optional: brand filter (uncomment and adjust if you filtered in Excel)
# BRANDS = ['bmw','volkswagen','mercedes-benz ag','volvo','toyota','ford','stellantis','nissan','kia','renault','byd','tesla','mazda','hyundai','polestar','gm','jlr','subaru']
# df['Bidder_Name'] = df['Bidder_Name'].astype(str).str.strip().str.lower()
# df = df[df['Bidder_Name'].isin(BRANDS)].copy()

# --- 4) Build the three comparable means ---
rows_total = len(df)
records = []
for c in present:
    s_raw = df[c]

    # Excel-like: zeros included, NaNs ignored, column-only view
    excel_like_mean = s_raw.mean()

    # Colwise-clean: treat zero as NA for ZERO_BAD, then mean (column-only view)
    s_col = s_raw.copy()
    if c in ZERO_BAD:
        s_col = s_col.mask(s_col == 0, pd.NA)
    colwise_clean_mean = s_col.mean()

    # Pipeline-style: drop rows that are invalid in ANY target column, then mean
    # (this is where most mismatches happen)
    mask_valid_all = pd.Series(True, index=df.index)
    for cc in present:
        s_tmp = df[cc]
        if cc in ZERO_BAD:
            s_tmp = s_tmp.mask(s_tmp == 0, pd.NA)
        mask_valid_all &= s_tmp.notna()
    s_pipe = df.loc[mask_valid_all, c]
    pipeline_mean = s_pipe.mean()

    records.append({
        "column": c,
        "rows_total": rows_total,
        "excel_like_nonNaN": int(s_raw.notna().sum()),
        "excel_like_mean": float(excel_like_mean) if pd.notna(excel_like_mean) else None,
        "colwise_clean_nonNaN": int(s_col.notna().sum()),
        "colwise_clean_mean": float(colwise_clean_mean) if pd.notna(colwise_clean_mean) else None,
        "pipeline_rows_used": int(mask_valid_all.sum()),
        "pipeline_mean": float(pipeline_mean) if pd.notna(pipeline_mean) else None,
        "zeros_count": int((s_raw == 0).sum())
    })

recon = pd.DataFrame.from_records(records)
print("\n=== Reconciliation: Excel vs Clean (per column) vs Pipeline (all columns valid) ===")
with pd.option_context("display.max_rows", None, "display.width", None):
    print(recon.to_string(index=False))
